name: AI Failure Triage
on:
  workflow_run:
    workflows: [ "CI", "Test Coverage", "Performance Gate (k6)" ]
    types: [ completed ]
jobs:
  triage:
    if: ${{ secrets.OPENAI_API_KEY != '' && github.event.workflow_run.conclusion == 'failure' }}
    runs-on: ubuntu-latest
    steps:
      - name: Download logs
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: ${{ github.event.workflow.name }}
          run_id: ${{ github.event.workflow_run.id }}
          if_no_artifact_found: ignore
      - name: Summarize failure
        uses: actions/github-script@v7
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const prompt = "Summarize the likely root cause from the following CI logs. Provide 3 concrete next steps.\nIf logs are empty, reply 'No logs'."
            let logs = ""
            try {
              const fs = require('fs'); const path = require('path')
              const files = fs.readdirSync(process.cwd())
              for (const f of files) if (f.endsWith('.txt')||f.endsWith('.log')||f.endsWith('.md')) logs += `\n## ${f}\n` + fs.readFileSync(f,'utf8').slice(0,100000)
            } catch (e) { logs = 'No logs' }
            const resp = await fetch("https://api.openai.com/v1/chat/completions", {
              method: "POST", headers: { "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`, "Content-Type":"application/json" },
              body: JSON.stringify({ model: "gpt-4o-mini", temperature: 0.2, messages: [{ role:"user", content: prompt + "\n\n" + logs }] })
            })
            let comment = "AI triage failed."
            if (resp.ok) { const data = await resp.json(); comment = data.choices?.[0]?.message?.content?.trim() || comment }
            await github.rest.issues.createComment({ owner: context.repo.owner, repo: context.repo.repo, issue_number: context.payload.workflow_run.pull_requests?.[0]?.number || 1, body: "CI failure triage:\n\n"+comment })
